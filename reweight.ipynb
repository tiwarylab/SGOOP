{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"This reweighting code is based on the algorithm proposed by Tiwary\n",
    "and Parrinello, JPCB 2014, 119 (3), 736-742. This is a modified version\n",
    "of te reweighting code based on earlier version (v1.0 - 23/04/2015) \n",
    "available in GitHub which was originally written by L. Sutto and \n",
    "F.L. Gervasio, UCL.\n",
    "\n",
    "Co-Author: Debabrata Pramanik       pramanik@umd.edu\n",
    "Co-Author: Zachary Smith            zsmith7@terpmail.umd.edu \"\"\"\n",
    "\n",
    "import os.path\n",
    "import argparse\n",
    "import numpy as np\n",
    "from math import log, exp, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Arguments\n",
    "gamma = 15                    # Biasfactor in well-tempered metadynamics.\n",
    "kT = 2.5                      # Temperature times Boltzmann constant.\n",
    "fesfilename = \"fes_\"          # FES file name start.\n",
    "numdat = 20                   # Number of FES files.\n",
    "col_fe = 1                    # Column of free energy.\n",
    "datafile = \"COLVAR_short5\"    # COLVAR file name.\n",
    "col_rewt = [2,3,5,6]          # COLVAR columns corresponding to RC variables.\n",
    "numrewt = 1                   # Number of reweighting iterations.\n",
    "col_bias = [7]                # COLVAR bias column.\n",
    "ngrid = 50                    # Number of grid bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    # Loads given files. Runs on import to prevent redundant loading.\n",
    "    global colvar,ebetac\n",
    "    # File Inputs\n",
    "    colvar = np.loadtxt(datafile)\n",
    "\n",
    "    # Calculating c(t):\n",
    "    # calculates ebetac = exp(beta c(t)), using eq. 12 in eq. 3 in the JPCB paper\n",
    "    #\n",
    "    ebetac = []\n",
    "\n",
    "    for i in range(numdat):\n",
    "        # set appropriate format for FES file names, NB: i starts from 0\n",
    "        fname = '%s%d.dat' % (fesfilename,i)\n",
    "\n",
    "        data = np.loadtxt(fname)\n",
    "        s1, s2 = 0., 0.\n",
    "        for p in data:\n",
    "            exponent = -p[col_fe]/kT\n",
    "            s1 += exp(exponent)\n",
    "            s2 += exp(exponent/gamma)\n",
    "        ebetac += s1 / s2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    # Used for import when running on the command line.\n",
    "    d = \"\"\"\n",
    "    It is a reweighting code to reweight some RC which is linear combination of a set\n",
    "    of order parameters which have the effect of biasing while the metadynamics run\n",
    "    were performed along some CV. Here, RC=c1*a1+c2*a2+c3*a3+... (where RC is the \n",
    "    reaction coordinate to be reweighted, c1, c2,... are the coefficients, a1, a2,\n",
    "    ... are the order parameters)\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=d, epilog=\" \")\n",
    "\n",
    "    parser.add_argument(\"-bsf\", type=float, default=15.0, help=\"biasfactor for the well-tempered metadynamics\")\n",
    "    parser.add_argument(\"-kT\", type=float, default=2.5, help=\"kT energy value in kJ/mol\")\n",
    "    parser.add_argument(\"-fpref\", default=\"fes\", help=\"free energy filenames from sum hills (default: %(default)s)\")\n",
    "\n",
    "    parser.add_argument(\"-nf\", type=int, default=100, help=\"number of FES input files (default: %(default)s)\")\n",
    "    parser.add_argument(\"-fcol\", type=int, default=2, help=\"free energy column in the FES input files (first column = 1) (default: %(default)s)\")\n",
    "\n",
    "    parser.add_argument(\"-colvar\", default=\"COLVAR\", help=\"filename containing original CVs, reweighting CVs and metadynamics bias\")\n",
    "    parser.add_argument(\"-rewcol\", type=int, nargs='+', default=[ 2 ], help=\"column(s) in colvar file containing the CV to be reweighted (first column = 1) (default: %(default)s)\")\n",
    "    #parser.add_argument(\"-coef\", type=float, nargs='+', default=[ 1 ], help=\"coefficients for each order parameters\")\n",
    "\n",
    "    parser.add_argument(\"-biascol\", type=int, nargs='+', default=[ 4 ], help=\"column(s) in colvar file containing any energy bias (metadynamic bias, walls, external potentials..) (first column = 1) (default: %(default)s)\")\n",
    "\n",
    "    parser.add_argument(\"-min\", type=float, nargs='+', help=\"minimum values of the CV\")\n",
    "    parser.add_argument(\"-max\", type=float, nargs='+', help=\"maximum values of the CV\")\n",
    "    parser.add_argument(\"-bin\", type=int, default=50, help=\"number of bins for the reweighted FES (default: %(default)s)\")\n",
    "\n",
    "    #parser.add_argument(\"-outfile\", default=\"fes_rew\", help=\"output FES filename (default: %(default)s)\")\n",
    "\n",
    "    parser.print_help()\n",
    "    return parser.parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(rc,commandline=False,sparse=False):\n",
    "    # Reweighting biased MD trajectory to unbiased probabilty along a given RC.\n",
    "    # By default (sparse=False) bins on the edge of the range with probabilities lower\n",
    "    # than 1/N where N is number of data points will be removed.\n",
    "    global gamma, kT, fesfilename, numdat, col_fe, datafile, col_rewt, numrewt, col_bias, ngrid, s_min, s_max\n",
    "    #### INPUTS\n",
    "    if commandline:\n",
    "        args = parser.parse_args()\n",
    "        gamma = args.bsf\n",
    "        kT = args.kT\n",
    "        fesfilename = args.fpref\n",
    "        numdat = args.nf\n",
    "        col_fe = args.fcol - 1\n",
    "        datafile = args.colvar\n",
    "        col_rewt = [ i-1 for i in args.rewcol ]\n",
    "        numrewt = 1\n",
    "        col_bias = [ i-1 for i in args.biascol ] \n",
    "        minz = args.min\n",
    "        s_min = np.min(minz)\n",
    "        s_min = np.reshape(s_min,newshape=(s_min.size,1))\n",
    "        maxz = args.max\n",
    "        s_max = np.max(maxz)\n",
    "        s_max = np.reshape(s_max,newshape=(s_max.size,1))\n",
    "        ngrid = args.bin\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    #Boltzmann-like sampling for reweighting\n",
    "    #\n",
    "\n",
    "    coeff = rc\n",
    "    rc_space = np.dot(colvar[:,col_rewt],coeff)\n",
    "    s_max = np.max(rc_space)\n",
    "    s_min = np.min(rc_space)\n",
    "\n",
    "    # build the new square grid for the reweighted FES\n",
    "    s_grid = [[ ]] * numrewt\n",
    "\n",
    "    #print(s_grid, numrewt)\n",
    "    #print(s_max, s_min, ngrid)\n",
    "\n",
    "    ds = (s_max - s_min)/(ngrid-1)\n",
    "    s_grid = [ s_min + n*ds for n in range(ngrid) ]\n",
    "    #print(s_max, s_min, ds)\n",
    "    \n",
    "    \n",
    "    \n",
    "    numcolv = np.shape(colvar)[0]\n",
    "\n",
    "    # initialize square array numrewt-dimensional\n",
    "    fes = np.zeros( [ ngrid ] * numrewt)\n",
    "\n",
    "    # go through the CV(t) trajectory\n",
    "    denom = 0.\n",
    "    i = 0\n",
    "    for row in colvar:\n",
    "        i += 1\n",
    "\n",
    "        # build the array of grid indeces locs corresponding to the point closest to current point\n",
    "        locs = [[ ]] * numrewt\n",
    "        for j in range(numrewt):\n",
    "            col = col_rewt[j]\n",
    "            #depending on the number of order parameters to be linearly added to get the RC to be reweighted, \n",
    "            #number of row[col]*q[0] terms will be added to the val below. \n",
    "            #val = (row[col]*q[0] + row[col+1]*q[1] + row[col+2]*q[2] + row[col+3]*q[3] + row[col+4]*q[4])/5\n",
    "            val = np.dot(row[col_rewt],coeff) \n",
    "            #val = row[col]*0 + row[col+1]*1\n",
    "            locs[j] = int((val-s_min)/ds) # find position of minimum in diff array\n",
    "\n",
    "        #find closest c(t) for this point of time\n",
    "        indx = int(ceil(float(i)/numcolv*numdat))-1\n",
    "        bias = sum([row[j] for j in col_bias])\n",
    "        ebias = exp(bias/kT)/ebetac[indx]\n",
    "        fes[locs] += ebias\n",
    "        denom += ebias\n",
    "\n",
    "    # ignore warnings about log(0) and /0\n",
    "    np.seterr(all='ignore')\n",
    "    fes /= denom\n",
    "    fes = -kT*np.log(fes)\n",
    "\n",
    "    # set FES minimum to 0\n",
    "    fes -= np.min(fes)\n",
    "    z = np.sum(np.exp(-fes/kT))\n",
    "    pavg = (np.exp(-fes/kT))/z\n",
    "    total = np.sum(pavg)\n",
    "    pnorm = pavg/total\n",
    "\n",
    "    if commandline:\n",
    "        #with open(out_fes_xy, 'w') as f:    \n",
    "        with open(\"prob_rew.dat\", 'w') as f:\n",
    "            for nx,x in enumerate(s_grid):\n",
    "                f.write('%20.12f %20.12f\\n' % (x,pnorm[nx]))\n",
    "        f.close()\n",
    "        \n",
    "    # Trimming off probability values less than one data point could provide\n",
    "    if not sparse:\n",
    "        cutoff = 1/np.shape(colvar)[0]\n",
    "        trim = np.nonzero(pnorm >= cutoff)\n",
    "        trimmed = pnorm[np.min(trim):np.max(trim)+1]\n",
    "        if np.min(trimmed) < cutoff:\n",
    "            cutoff = np.min(trimmed)\n",
    "            trim = np.nonzero(pnorm >= cutoff)\n",
    "            trimmed = pnorm[np.min(trim):np.max(trim)+1]\n",
    "        return trimmed\n",
    "    return pnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebias(rc,old_rc,old_p,commandline=False,sparse=False):\n",
    "    # Reweighting biased MD trajectory to a probability along a RC with SGOOP-bias along a second RC.\n",
    "    # By default (sparse=False) bins on the edge of the range with probabilities lower\n",
    "    # than 1/N where N is number of data points will be removed.\n",
    "    global gamma, kT, fesfilename, numdat, col_fe, datafile, col_rewt, numrewt, col_bias, ngrid, s_min, s_max\n",
    "    #### INPUTS\n",
    "    if commandline:\n",
    "        args = parser.parse_args()\n",
    "        gamma = args.bsf\n",
    "        kT = args.kT\n",
    "        fesfilename = args.fpref\n",
    "        numdat = args.nf\n",
    "        col_fe = args.fcol - 1\n",
    "        datafile = args.colvar\n",
    "        col_rewt = [ i-1 for i in args.rewcol ]\n",
    "        numrewt = 1\n",
    "        col_bias = [ i-1 for i in args.biascol ] \n",
    "        minz = args.min\n",
    "        s_min = np.min(minz)\n",
    "        s_min = np.reshape(s_min,newshape=(s_min.size,1))\n",
    "        maxz = args.max\n",
    "        s_max = np.max(maxz)\n",
    "        s_max = np.reshape(s_max,newshape=(s_max.size,1))\n",
    "        ngrid = args.bin\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    #Boltzmann-like sampling for reweighting\n",
    "    #\n",
    "\n",
    "    coeff = rc\n",
    "    rc_space = np.dot(colvar[:,col_rewt],coeff)\n",
    "    bias_space = np.dot(colvar[:,col_rewt],old_rc)\n",
    "    \n",
    "    s_max = np.max(rc_space)\n",
    "    s_min = np.min(rc_space)\n",
    "    \n",
    "    \n",
    "    b_max = np.max(bias_space)\n",
    "    b_min = np.min(bias_space)\n",
    "    \n",
    "    # build the new square grid for the reweighted FES\n",
    "    s_grid = [[ ]] * numrewt\n",
    "\n",
    "    #print(s_grid, numrewt)\n",
    "    #print(s_max, s_min, ngrid)\n",
    "\n",
    "    ds = (s_max - s_min)/(ngrid-1)\n",
    "    db = (b_max - b_min)/(ngrid-1)\n",
    "    s_grid = [ s_min + n*ds for n in range(ngrid) ]\n",
    "    #print(s_max, s_min, ds)\n",
    "    \n",
    "    \n",
    "    \n",
    "    numcolv = np.shape(colvar)[0]\n",
    "\n",
    "    # initialize square array numrewt-dimensional\n",
    "    fes = np.zeros( [ ngrid ] * numrewt)\n",
    "\n",
    "    # go through the CV(t) trajectory\n",
    "    denom = 0.\n",
    "    i = 0\n",
    "    for row in colvar:\n",
    "        i += 1\n",
    "\n",
    "        # build the array of grid indeces locs corresponding to the point closest to current point\n",
    "        locs = [[ ]] * numrewt\n",
    "        blocs = [[ ]] * numrewt\n",
    "        for j in range(numrewt):\n",
    "            col = col_rewt[j]\n",
    "            #depending on the number of order parameters to be linearly added to get the RC to be reweighted, \n",
    "            #number of row[col]*q[0] terms will be added to the val below. \n",
    "            #val = (row[col]*q[0] + row[col+1]*q[1] + row[col+2]*q[2] + row[col+3]*q[3] + row[col+4]*q[4])/5\n",
    "            val = np.dot(row[col_rewt],coeff) \n",
    "            bval = np.dot(row[col_rewt],old_rc)\n",
    "            locs[j] = int((val-s_min)/ds) # find position of minimum in diff array\n",
    "            blocs[j] = int((bval-b_min)/db)\n",
    "\n",
    "        #find closest c(t) for this point of time\n",
    "        indx = int(ceil(float(i)/numcolv*numdat))-1\n",
    "        bias = sum([row[j] for j in col_bias])\n",
    "        ebias = exp(bias/kT)/(ebetac[indx]*old_p[blocs])\n",
    "        fes[locs] += ebias\n",
    "        denom += ebias\n",
    "\n",
    "    # ignore warnings about log(0) and /0\n",
    "    np.seterr(all='ignore')\n",
    "    fes /= denom\n",
    "    fes = -kT*np.log(fes)\n",
    "\n",
    "    # set FES minimum to 0\n",
    "    fes -= np.min(fes)\n",
    "    z = np.sum(np.exp(-fes/kT))\n",
    "    pavg = (np.exp(-fes/kT))/z\n",
    "    total = np.sum(pavg)\n",
    "    pnorm = pavg/total\n",
    "\n",
    "    if commandline:\n",
    "        #with open(out_fes_xy, 'w') as f:    \n",
    "        with open(\"prob_rew.dat\", 'w') as f:\n",
    "            for nx,x in enumerate(s_grid):\n",
    "                f.write('%20.12f %20.12f\\n' % (x,pnorm[nx]))\n",
    "        f.close()\n",
    "        \n",
    "    # Trimming off probability values less than one data point could provide\n",
    "    if not sparse:\n",
    "        cutoff = 1/np.shape(colvar)[0]\n",
    "        trim = np.nonzero(pnorm >= cutoff)\n",
    "        trimmed = pnorm[np.min(trim):np.max(trim)+1]\n",
    "        if np.min(trimmed) < cutoff:\n",
    "            cutoff = np.min(trimmed)\n",
    "            trim = np.nonzero(pnorm >= cutoff)\n",
    "            trimmed = pnorm[np.min(trim):np.max(trim)+1]\n",
    "        return trimmed\n",
    "    return pnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight2d(d1,d2,size=100,data=None):\n",
    "    # Reweighting biased MD trajectory to a 2D probability.\n",
    "    global gamma, kT, fesfilename, numdat, col_fe, datafile, col_rewt, numrewt, col_bias, ngrid, s_min, s_max,fes\n",
    "    if data != None:\n",
    "        datafile = data\n",
    "        load()\n",
    "    numcolv = np.shape(colvar)[0]\n",
    "\n",
    "    # initialize square array numrewt-dimensional\n",
    "    fes = np.zeros(numcolv)\n",
    "\n",
    "    # go through the CV(t) trajectory\n",
    "    denom = 0.\n",
    "    i = 0\n",
    "    for row in colvar:\n",
    "        i += 1\n",
    "\n",
    "        # build the array of grid indeces locs corresponding to the point closest to current point\n",
    "        locs = [[ ]] * numrewt\n",
    "        for j in range(numrewt):\n",
    "            col = col_rewt[j]\n",
    "        indx = int(ceil(float(i)/numcolv*numdat))-1\n",
    "        bias = sum([row[j] for j in col_bias])\n",
    "        ebias = exp(bias/kT)/ebetac[indx]\n",
    "        fes[i-1] = ebias\n",
    "        denom += ebias\n",
    "\n",
    "    hist = np.histogram2d(colvar[:,d1],colvar[:,d2],size,weights=fes)\n",
    "    hist = hist[0]\n",
    "    pnorm = hist/np.sum(hist)\n",
    "    return pnorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
